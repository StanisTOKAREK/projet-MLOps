ğŸš€ Projet MLOps - Industrialisation du modÃ¨le Iris
Ce dÃ©pÃ´t contient l'infrastructure nÃ©cessaire pour automatiser le cycle de vie d'un modÃ¨le de classification Iris. L'objectif est de rÃ©pondre aux exigences de production : reproductibilitÃ©, sÃ©curitÃ©, et observabilitÃ©.

ğŸ—ï¸ Structure du projet
src/ : Scripts d'entraÃ®nement (train.py) avec gestion de la reproductibilitÃ© (seed) et logique d'infÃ©rence.

api/ : Service FastAPI pour l'exposition du modÃ¨le.

docker/ : Dockerfiles optimisÃ©s pour le training et le serving.

models/ : Artefacts du modÃ¨le (.joblib) et suivi des performances (metrics.json).

data/ : Dossier rÃ©servÃ© au stockage des datasets.

ğŸ› ï¸ Guide de dÃ©marrage (Ã‰quipe)
Le projet est entiÃ¨rement conteneurisÃ©. Vous n'avez pas besoin d'installer de dÃ©pendances Python sur votre machine si vous utilisez Docker ou GitHub Codespaces.

1. Lancer l'environnement
Pour entraÃ®ner le modÃ¨le et dÃ©marrer l'API automatiquement, exÃ©cutez la commande suivante Ã  la racine :

Bash
docker compose up --build
2. Tester l'API
Une fois les conteneurs actifs :

Health Check : Allez sur /health pour vÃ©rifier l'Ã©tat du service et les mÃ©triques de latence.

InfÃ©rence : La documentation interactive (Swagger) est disponible sur /docs. Vous pourrez y tester des prÃ©dictions manuellement.

âš™ï¸ Choix techniques
ğŸ”’ SÃ©curitÃ©
PrivilÃ¨ges rÃ©duits : Les images Docker tournent via un utilisateur non-root (mluser).

HygiÃ¨ne du code : Un fichier .dockerignore exclut les fichiers sensibles ou inutiles du build.

Validation : Les types de donnÃ©es entrants sont contrÃ´lÃ©s par Pydantic pour Ã©viter les erreurs d'exÃ©cution.

ğŸ§ª ReproductibilitÃ©
Seed fixe : Utilisation d'une graine alÃ©atoire fixe (SEED = 42) pour garantir des rÃ©sultats d'entraÃ®nement identiques d'un environnement Ã  l'autre.

Versioning : Chaque run gÃ©nÃ¨re un fichier metrics.json pour assurer la traÃ§abilitÃ© des performances.

ğŸ“ˆ ObservabilitÃ©
Logs JSON : L'API gÃ©nÃ¨re des logs structurÃ©s facilitant l'ingestion par des outils de monitoring (ELK, Datadog, etc.).

Monitoring : Suivi en direct de la latence et du statut du modÃ¨le via l'endpoint de santÃ©.

ğŸš¨ Gestion des incidents (Point 9)
ScÃ©nario : DÃ©tection d'une baisse de performance ou dÃ©rive des donnÃ©es (Data Drift). ProcÃ©dure de remÃ©diation :

Identification de la dÃ©rive via les logs JSON.

Mise Ã  jour du dataset dans le dossier data/.

RÃ©-entraÃ®nement du modÃ¨le : docker compose up --build training.

L'API charge automatiquement le nouvel artefact au redÃ©marrage, sans modification du code.

Projet rÃ©alisÃ© dans le cadre du module MLOps (M2).
